
* 数据结构

	* 线性表
		* 数组

		* 链表
			* 双向链表

		* 队列
			* 先进后出

		* 栈
			* 先进先出

	* 树
		* 二叉树

		* 红黑树
			\Property
				* Every node is either red or black.
				* The root is black.
				* Every leaf (NIL) is black.
				* If a node is red, then both its children are black.
				* For each node, all simple paths from the node to descendant leaves contain the same number of black nodes.

		* 堆
			\Property
				* h深的树, 元素个数为$\{ 2^h, 2^{h+1} - 1 \}$ 
					\Proof
						* 最多, 满树
						$n = \sum_{i=0}^h 2^i = \frac{1 - 2^{h+1}}{1 - 2} = 2^{h+1} - 1$
						* 最少, 底层余一
						$n = \sum_{i=0}^{h-1} 2^i + 1 = 2^h$

				* n元堆的高度为$⌊\lg n⌋$
					\Proof
						h深的树, 元素有$\{ 2^h, 2^{h+1} - 1 \}$
						. $∴ lg n \in [h, h + 1]$
						故下取整为$ h = ⌊\lg n⌋$

	* 图

	* Hash表

* 算法
	* 排序
		* 快速排序
			\Property
				* 时间复杂度: 上限n^2，大概率平均值n log(n)
				*	[流程]: 
				*		* 最后元素作为参考元素[Ref]，[border]分割比参考元素大或小的界限，指向大的最初段
						* [ai] 从第一元素开始，直至 Ref 前一元素位置
						*	1).若 ai >=Ref, 不处理
							2).若 ai < Ref, 
								ai 与 border元素交换位置, border++
						* 遍历结束后, 交换Ref 与 border
						* Ref 左右比他大/小的两方元素，分别从头开始. 
			
		* 堆排序

		* 选择排序

		* 冒泡排序

		* 归并排序

		* 希尔排序

	* 图论
		* 图

		* 最短路径
			* Dijkstra算法

			* Floyd算法
				[输入]:	* 图的邻接矩阵Graph
				[输出]: * 距离矩阵Distance	* 后继节点矩阵Path
					* 邻接矩阵Graph, 即.图的权值矩阵
					* 距离矩阵Distance: i到j最短路径长度
					* 后继节点矩阵Path: 记录两点间的最短路径, 表示从Vi到Vj需要经过的点
				\bf{原理}
					* Floyd的本质的动态规划, Dijkstra的本质是贪心
					* 状态转移方程:
						Distance[i,j] = min{ Distance[i,k] + Distance[k,j] , Distance[i,j] }

				\bf{流程}
					* 初始化距离矩阵Distance = 权值矩阵Graph
						初始化后继矩阵Path(i,j) = j
					* 对于每一对顶点 i 和 j, 看是否存在点 k 使得u->k->v比已知路径更短
							即. Distance[i,j] = min{ Distance[i,k] + Distance[k,j] , Distance[i,j] }
						若是,则更新Distance, Path(i,j) = k
				
			\Property
				* 时间复杂度:
					* Floyd	时间复杂度$O(V^3)$, 3个for循环嵌套; 空间复杂度$O(V^2)$, 2个矩阵.
					* Dijkstra 时间复杂度$O(V^2)$

				* 对比Dijkstra \& Floyd
					Dijkstra 一次只能算出给定两点间的最短路径. 
					Floyd 一次可以算出任意两点间的最短路径. 

		* 最小生成树
			* Prim
				[输入]: 图的邻接链表[Graph], 节点数量[n]
				[输出]: 最小生成树,每一条有向边的 起点[TreeU],终点[TreeV],总边数[TreeCur]
				[原理]: 按点贪心, 每次加入已搜索点集u的最短边(u,v)，其中v不属于已搜索点集的点v

				\bf{流程}
					* 初始化[已搜点集 VertexNew]
					* 将第一个图的节点, 加入VertexNew
					* 开始迭代, 直至所有节点均已搜索完成, 即VertexNew已满
						* 在已搜点集, 寻找最短边(u,v), 其中u∈VertexNew, v ∉ VertexNew
						* 将边(u,v)加入最小生成树， 将v加入VertexNew

			* Kruskal
				\bf{流程}
					* 初始化未搜索边集EdgeNew = E0图边集
					* 开始迭代,直至未搜索边集为空集
						* 在边集合,选择最短边(u,v)
						* 若(u,v)不在同一颗树, u,v所在两棵树合并,(u,v)加入该树
						* 点集中删(u,v)
					* 最后剩下的那棵树,就是最小生成树

			\Property
				* 时间复杂度:
					* Prim 时间复杂度 $O(E·logV)$
					* Kruskal 时间复杂度 $O(E·logV)$
				* 对比Prim \& Kruskal
					Kruskal	是按边贪心，适合稀疏图. 
					Prim 是按点贪心，适合稠密图. 

		* 网络最大流
			* Dinic
				[原理]: 贪心 + "反悔"机制
				增广路: 就是源->汇的一条路径. 
					利用深搜DFS，找增广路. 
					利用广搜BFS，确定此时各顶点的层次. 
					利用添加反向边，协助"反悔". 
					广搜BFS是Dinic对于EK的优化. 
					广搜BFS，用队列queue. 
					深搜BFS，用递归or栈stack. 

		* 商旅问题
			\def{商旅问题} 遍历所有给定点的最短闭合路径.

	* 动态规划

	* 插值
		* \Algorithm{Lagrange插值}	
			$
				f(x) = \sum_{i=1}^n  y_i · f_i(x)
				f_i(x) = \prod_{j=1,i≠j}^n  \frac{x - x_j}{x_i - x_j}
			$
			第N点y = 基函数1 × 第1点y + 基函数2 × 第2点y + 基函数3 × 第3点y
			基函数状态2 = (输入X-第1点x)(输入X-第3点x) / (第2点x-第1点x)(第2点x-第3点x)

		* \Algorithm{样条插值}	
			通过求解三弯矩方程组得出曲线函数组的过程

		* \Algorithm{Kriging插值}

			* \Algorithm{普通Kriging插值}
				* 目的:
					空间插值. 满足假设:
					* 空间属性z是均一的. 对空间任意一点，都有相同期望、方差.
				* 优化问题:
					$
						min \quad&	var = 2\sum w_i \gamma_{i0} - \sum\sum w_i w_j \gamma_{ij} - \gamma_{00}
						s.t. \quad&	\sum w_i = 1
							\gamma_{ij} = \sigma^2 - C_{ij} = E[(Z(x_i) - Z(x_j))^2]
					$
				* 步骤:
					* 确定半方差函数$\gamma(xi,xj) = E[(Z(x_i) - Z(x_j))^2]$
						确定半方差函数与两点间距离的函数关系.
					* 计算权值
						权值计算方程:
						$
							[\mb w_1 \\ \vdots \\ w_n \\ \mu \me] = [\mb \gamma(x_1,x_1) & ... & \gamma(x_1,x_n) & 1 \\ ... & ... & ... & ... \\  \gamma(x_n,x_n) & ... & \gamma(x_n,x_n) & 1 \\ 1 & ... & 1 & 0 \me]^{-1} [\mb \gamma(x_1,x^*) \\ \vdots \\ \gamma(x_1,x^*) \\ 1 \me]
						$
					* 计算插值点结果
						$f(x) = \sum w_i(x) f(x_i)$
				* 原理:
					* $f(x) = \sum w_i(x) f(x_i)$
						$\tilde z$: 估计值	z : 实际值
						求解权重系数: 使其为满足插值点处，估计值与真实值差最小的一组系数.
					* 对空间任意一点，都有相同期望、方差. 即:
						$
							E	(z(x,y)) = μ
							Var	(z(x,y)) = \sigma^2
							=> z(x,y) = μ + R(x,y)    Var(R(x,y)) = \sigma^2
						$
					* 约束方程 —— 无偏估计条件 $E(\tilde z - z) = 0$
						$
							=> E(\tilde z - z) = E(\sum w_i z_i - z) = μ\sum w_i - μ = 0
							=> \sum w_i = 1
						$
					* 目标函数 —— 估计误差 $var = Var(\tilde z - z)$
						$
							=> var = Var(\sum w_i z_i - z) = \sum\sum w_i w_j Cov(zi,zj) - 2\sum w_i Cov(zi,z) + cov(z,z)
							=> var = \sum\sum w_i w_j C_{ij} - 2\sum w_i C_i0 + cov_{00} \quad; (C_{ij} = Cov(zi - μ,z - μ))
						$
					* 定义 半方差函数$\gamma_{ij} = \sigma^2 - C_{ij}$
						$
							=> var = 2\sum w_i \gamma_i0 - \sum\sum w_i w_j \gamma_{ij} - \gamma_{00}
						$
					* 凸优化问题构建完成:
						$
							min		var = 2\sum w_i \gamma_i0 - \sum\sum w_i w_j \gamma_{ij} - \gamma_{00}
							s.t.	\sum w_i = 1
						$
						Lagrange函数	$L(w_i, \lambda) = var + \lambda(\sum w_i - 1)$
						Lagrange对偶	$G(\lambda) = inf L(w_i, \lambda)$
						$L(W,\lambda)$求导, 当导数为0时, 取得极值
						即. 得到权值计算方程.
					* 半方差函数$\gamma_{ij} = \sigma^2 - C_{ij} = E[(Z(x_i) - Z(x_j))^2]$
						∵地理学第一定律: 空间上相近的属性相近.
						∴$\gamma_{ij}$与两点间距离，存在函数关系
						将所有d和$\gamma$绘成散点图，寻找最优曲线拟合d与$\gamma$，得到函数关系式.

				\Codes
					def variogram(x1, y1, x2, y2):
						return sqrt( (x1 - x2)^2 + (y1 - y2)^2 )^3

					# 普通Kriging插值
					def Interpolate(x1, y1, z1)
						for r in range(n)
							for c in range(n)
								x = x1[r]
								y = y1[c]
								R0 = ones(N+1, N+1)
								R  = zeros(N+1)

								#R0
								R0[N, N] = 0
								for i in range(N):
									for j in range(N):
										R0[i, j] = variogram(x0[i], y0[i], x0[j], y0[j])

								#R
								R[N] = 1
								for i in range(N)
									R[i] = variogram(x0[i], y0[i], x, y)

								#lamb
								lamb = matmul(linalg.inv(R0), R)
								for i in range(N):
									z1[r, c] += lamb[i] * z0[i]
								z1[r, c] += lamb[N]

		* \Algorithm{反距离加权插值}
		
			\Codes
				x1 = arange(-1,1,0.05)
				y1 = arange(-1,1,0.05)
				z1 = zeros(40,40)
				
				# 反距离加权插值
				def Interpolate(x1, y1, z1)
					for r in range(40)
						for c in range(40)
							x = x1[r]
							y = y1[c]
							d0 = 0

							for i in range(N)
								d0 += 1 / ((x - x0[i])^2 + (y - y0[i])^2)

							for i in range(N)
								d = (x - x0[i])^2 + (y - y0[i])^2
								w = (1 / d) / d0
								z1[r,c] += w * z0[i]